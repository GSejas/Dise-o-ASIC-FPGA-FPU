<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML Basic 1.0//EN"
      "http://www.w3.org/TR/xhtml-basic/xhtml-basic10.dtd">
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=iso-8859-1" />
  <title>FloPoCo user manual</title>
  <meta name="generator" content="Amaya 9.54, see http://www.w3.org/Amaya/" />
</head>

<body>
<h1>FloPoCo user manual</h1>

 <img src="FloPoCoLogoSmall.png">


<hr/>
<h2>Installation</h2>

<h3>Single-line installation on Ubuntu 10.04LTS to 11.10</h3>
Copy this in a dash/bash shell (and enter your password when prompted):

<p><code>yes | sudo apt-get install g++ libgmp3-dev libmpfr-dev libxml2-dev bison libmpfi-dev flex cmake && wget http://perso.ens-lyon.fr/damien.stehle/downloads/libfplll-3.0.12.tar.gz && tar xzf libfplll-3.0.12.tar.gz && cd libfplll-3.0.12/ && ./configure && make -j2  && sudo make install && cd .. && wget https://gforge.inria.fr/frs/download.php/28248/sollya-2.9.tar.gz && tar xzf sollya-2.9.tar.gz && cd sollya-2.9/ && ./configure && make -j2  && sudo make install && cd .. && wget https://gforge.inria.fr/frs/download.php/29991/flopoco-2.3.0.tgz && gunzip < flopoco-2.3.0.tgz    | tar xvf - && cd flopoco-2.3.0/ && cmake . && make -j2  && ./flopoco</code></p>

<h3>Generic installation instructions</h3>

<p>FloPoCo may be compiled either using CMake or the autotools. 
The recommended way is CMake, which is available for most Unix and
Linux distributions and for Windows. If you prefer to use the autotools read the README.autotools file.</p>

<p><a href="http://www.cmake.org/">CMake</a> is included in  mainstream Linux/Unix distributions, and is available for other operating systems, including Windows.</p>

<p>FloPoCo also depends on the <a href="http://www.mpfr.org">MPFR library</a>, on the C++ interface to GMP (which may or may not be a dependency of MPFR) and on flex++,
all of which are probably available in your favourite Linux/Unix
distribution. </p>

<p>Optionally, you may want to link FloPoCo
against <a href="http://sollya.gforge.inria.fr/">Sollya</a>. This
enables more operators (HOTBM, FunctionEvaluator). For this purpose, you
must download,
compile and install <a href="http://sollya.gforge.inria.fr/">Sollya</a>.
FloPoCo is demonstrated to work with version 2.0 of Sollya and should work with future releases.
</p>

<p>Compilation is a two-step process:</p>

<p><code>cmake .</code></p>

<p><code>make</code></p>


<p>The adventurous may get FloPoCo from its <a
href="https://gforge.inria.fr/scm/?group_id=1030">subversion
repository</a>.</p>


<hr/>
<h2>Command-line interface</h2>

<p>FloPoCo is a command-line tool. The general syntax is</p>

<p><code>flopoco &lt;options&gt; &lt;operator specification
list&gt;</code></p>

<p>FloPoCo will generate a single VHDL file (named by default
<code>flopoco.vhdl</code>) containing synthesisable descriptions of all the
operators listed in <code>&lt;operator specification list&gt;</code>, plus
possibly sub-operators instanciated by them. To use these operators in your
design, just add this generated file to your project.</p>

<p>FloPoCo will also issue a report with useful information about the generated operators, such as the pipeline depth. In addition, three levels of verbosity are available.</p>

<h3>Examples</h3>

<p><code>./flopoco IntConstMult 16 12345</code></p>

<p>produces a file <code>flopoco.vhdl</code> containing a single operator for
the integer multiplication of an input 16-bit number by the constant 12345.
The VHDL entity is named after the operator specification, here
<code>IntConstMult_16_12345</code>.</p>

<p><code>./flopoco IntConstMult 16 12345 IntConstMult 16 54321</code></p>

<p>produces a file <code>flopoco.vhdl</code> containing two VHDL entities and
their architectures, for the two given constant multipliers. </p>

<p><code>./flopoco FPConstMult 8 23 8 23 0 -50 1768559438007110</code></p>

<p>produces a file flopoco.vhdl containing two VHDL entities, one for the
specified constant floating-point multiplier by 1768559438007110x2<sup>-50</sup>, and
the other one for a needed sub-component (an integer multiplier for the
significand multiplication).</p>

<h3>Options</h3>

<p>Several transversal options are available and will typically change the
operators occuring after them in the list. For
instance <code>-frequency=300</code> sets the target
frequency. The <code>-name=UserProvidedName</code> option replaces the
(ugly and parameter-dependent) name generated by FloPoCo for the next
operator with a user-provided one. This allows in particular to change
parameters while keeping the same entity name, so that these changes
are transparent to the rest of the project. Options related to pipelining are reviewed below.</p>

<p>The <code>-target</code> option selects the target FPGA family. We
try to optimize for the highest speed grade available for this
family (see <a href="#pipelining">below</a> for pipelining options).</p>
<h3>Built-in help</h3>

<p>To obtain a concise list of the available operators and options, simply
type</p>

<p><code>./flopoco </code></p>

<p>In addition this help may be more in sync with the code than this file,
especially if you are using a svn snapshot.</p>

<h3>Helper programs</h3>

<p>The FloPoCo distributions also includes useful programs for converting the
binary string of a floating-point number to human-readable form
(<code>bin2fp</code>) and back (<code>fp2bin</code>). The
<code>longacc2fp</code> utility converts the fixed-point output of the
LongAcc operator (see below) to human-readable form.</p>

<p></p>

<hr/>
<h2>Floating-point format</h2>

<p>The floating-point format used in FloPoCo is identical to the one used in  <a
href="http://www.ens-lyon.fr/LIP/Arenaire/Ware/FPLibrary/">FPLibrary</a>. It is  inspired from the IEEE-754 standard.</p>

<p>
An FP  number is a bit vector consisting of 4 fields. From left to right: 
<dl>
  <dt>A 2-bit exception field</dt>
    <dd>00 for zero, 01 for normal numbers, 10 for infinities, and 11 for NaN</dd>
  <dt>A sign bit</dt>
    <dd>0 for positive, 1 for negative</dd>
  <dt>An exponent field on wE bits</dt>
    <dd>It is biased as in IEEE-754. The smallest possible FP numbers have exponent field 00...00, the FP  number 1.0 has the exponent field 011...11 and the largest possible FP numbers have exponent 11...11 </dd>
  <dt>A fraction field on wF bits</dt>
    <dd>The actual significand has an implicit leading 1, so the fraction field ff...ff  represents the significand 1.ff...ff</dd>
</dl>
 </p>

<p>The format is therefore parameterized by to positive integers wE
and wF which define the sizes of the exponent and fraction fields
respectively.</p>

<p>The utilities <code>fp2bin</code> and <code>bin2fp</code> will allow
you to get familiar with the format and set up test benches. </p>

<h3>Difference between FloPoCo format and IEEE-754 format</h3>


<p>
There are two main differences between the format (wE=8, wF=23) and the IEEE-754 single precision format (the same holds for double).
</p>
<ul> 
  <li><p>Exceptional cases (zeroes, infinities and Not a Number or NaN)
  are encoded as separate bits in FloPoCo, instead of being encoded as
  special exponent values in IEEE-754. This saves quite a lot of decoding/encoding
  logic. The main drawback of
  this format is when results have to be stored in memory, where they
  consume two more bits. However,  FPGA embedded
  memory can accomodate 36-bit data, so adding two bits to a 32-bit IEEE-754 format is harmless as long as data resides within the FPGA.</p><p> As a side effect, the exponent
  can take two more values in FloPoCo than in IEEE-754 (one for very large numbers, one for very small ones).</p>
  </li>
  <li>FloPoCo does not support subnormal numbers. If you think you
	 need subnormal numbers, consider adding one bit to your exponent field
	 instead: you will thus get all the subnormals, and many more. If you
	 are still not convinced, maybe you are right: please get in touch with
	 us.
  </li>  
</ul>

<p>
 Note that anyway, FloPoCo provides conversion operators from and to IEEE-754 formats (single and double precision).
</p>

<hr/>
<h2>LNS format</h2>

<p>Numbers in the Logarithm Number System used in FloPoCo have an encoding
similar to the floating-point format. It is also the same as the one used in
<a
href="http://www.ens-lyon.fr/LIP/Arenaire/Ware/FPLibrary/">FPLibrary</a>.</p>

<p>Its fields are:
<dl>
  <dt>A 2-bit exception field</dt>
    <dd>Same encoding as floating-point: 00 for zero, 01 for the general case, 10 for infinities, and 11 for NaN</dd>
  <dt>A sign bit</dt>
    <dd>0 for positive, 1 for negative</dd>
  <dt>The integral part of the exponent on wE bits</dt>
  <dt>The fractional part of the exponent on wF bits</dt>
    <dd>The fixed-point exponent is encoded in two's-complement.</dd>
</dl>
</p>
<p>Reasonable values are 4 to 8 for wE, and 8 to 20 for wF.
Other values are still allowed, including negative wE. Use at your own risk.</p>


<hr/>
<h2><a name="pipelining"></a>Pipelining</h2>

<p>An operator may be combinatorial, or pipelined. A combinatorial operator has pipeline depth 0. An operator of pipeline depth 1 is obtained by inserting one and only one register on any path from an input to an output. Hopefully, this divides  the critical path delay by almost 2.  An operator of pipeline depth 2 is obtained by inserting two register levels, etc.</p>

<p>It should be noted that, according to this definition, pipelined
operators usually do not directly buffer neither their inputs nor
their outputs. For instance, connecting the input of a 400MHz operator
to the output of another 400MHz operator may well lead to a circuit
working at 200MHz only. It is the responsibility of the user or
calling program to insert one more level of registers between two
FloPoCo operators. This convention may be felt as a burden to the
user, but it is the most sensible choice. It makes it possible to
assemble sub-component without inserting registers in many situations,
thus reducing the latency of complex components. Besides, different
application contexts may have different policies (registers on output,
or registers on input). <p>

<p>Two command-line options control the pipelining of the FloPoCo
operators that follow them.

<dl>
  <dt><code>-pipeline=[yes|no]</code>  (default yes)</dt>
  <dt><code>-frequency=[frequency in MHz]</code>  (default 300)</dt>
    <dd>Sets the target frequency. If the <code>-pipeline</code>
    option is set, then FloPoCo will try to pipeline the operator to
    the given frequency. It will report a warning if it fails -- or if
    frequency-directed pipelining is not yet implemented for this
    operator.
	 </dd>
    <dd>
		Requires the operators to be pipelined. If <code>no</code>, the operator will be combinatorial. If <code>yes</code>,  registers
		may be inserted if needed to reach the target frequency. 
	 </dd>
</dl>
</p>


<p>The philosophy of FloPoCo's approach to pipelining is the following:
  <ul>
	 <li>FloPoCo's approach is to provide a fair estimate of the pipeline
		depth required to obtain a given frequency, and a sensible placement
		of registers.</li>
	 <li>FloPoCo's pipelining effort is always tentative: You may not
		get the frequency you asked (sometimes you will even get a
		higher one). However, in such cases, increasing or decreasing
		the target frequency should also increase or decrease the
		obtained frequency. Note that you may do so on a per-operator
		basis, as in: <code>flopoco -frequency=200 FPAdder 11 52
		-frequency=300 FPMultiplier 8 23</code></li>

	 <li> If the obtained frequency is higher than needed, reducing
	 the <code>-frequency</code> option may save resources.</li>

	 <li> The pipeline built by FloPoCo may depend on the target. When
	 tuning it, we use the best possible speed grade for a given target
	 family, for insance -12 for Virtex-4. If you want to target a FPGA
	 with a lower speed grade, you may need to
	 update <code>-frequency</code> accordingly.</li>

	 <li> Better results will always be obtained by using retiming
		tools, which can work on a circuit netlist after technology
		mapping. The pipeline built by FloPoCo should help these
		retiming tools converge faster to a global optimal.</li>
  </ul>
</p>
<p>Note that not all operators support pipelining (utimately they all will). They are mentionned in the command-line help.
</p>

<hr/>
<a NAME="AvailableOperators"> </a> 
<h2>Available operators</h2>

<p>Here is the list of operators that can be generated by
FloPoCo. This list may not be fully up-to date... the code is the
reference.</p>

<h3>Useful building blocks for FP operators</h3>

<dl>
  <dt><code style="color: blue;">LeftShifter wIn MaxShift</code> </dt>
    <dd>Left barrel shifter. It has two inputs, the data to shift and a shift
      value. The width of the latter is deduced from MaxShift, which is the
      maximum shift distance. This operator will be pipelined to match target
      frequency.</dd>
  <dt><code style="color: blue;">RightShifter wIn MaxShift</code> </dt>
    <dd>Same, but to the right.</dd>
  <dt><code style="color: blue;">LZOC wIn wOut</code></dt>
    <dd>Leading Zero/One Counter.</dd>
  <dt><code style="color: blue;">LZOCShifterSticky wIn wOut computeSticky countType</code></dt>
    <dd>Leading Zero/One Counter merged with a shifter. If
    computeSticky=0 the bits shifted out are discarded, if 1 they are
    ORed into a sticky bit. If countType=0, a leading zero counter is
    built, if 1 a leading one counter is built, if -1 the value to
    count is input from an extra input port.</dd>
</dl>

<h3>Pipelined integer standard operators</h3>
<dl>
  <h4><i> Adders </i></h4>
  <dt><code style="color: blue;">IntAdder wIn</code></dt>
    <dd>Integer adder. In modern VHDL, integer addition is expressed by a +
      and one usually needn't define an entity for it. However, this operator
      will be pipelined if the addition is too large to be performed at the
      target frequency. </dd>
  <dt><code style="color: blue;">MyIntAdder wIn optimizeType srl implementation bufferedInputs</code></dt>    
      <dd> IntAdder in manual mode. The option <code>optimizeType=<0,1,2,3></code> 
      where <code>0=LUT 1=REG 2=SLICE 3=LATENCY</code> allows selecting the different 
      optimization criteria. <code>srl=<0,1></code> allows generating architectures optimized
      for the use of hardware shift registers. The architecture can also adapt if inputs of the 
      adder are already buffered or not using the option <code>bufferedInputs=<0,1></code>.
      Automatic design space exploration is performed by setting <code>implementation=-1</code>.
      Forcing architecture selection can be done by setting <code>implementation=<0,1,2></code>
      where <code>0=Classical, 1=Alternative, 2=Short-Latency</code>. Please check out this
      <a href="http://prunel.ccsd.cnrs.fr/docs/00/47/57/80/PDF/RR-LIP-2010-16.pdf">article</a>
      for more details.
  <dt><code style="color: blue;">IntDualSub wIn opType</code></dt>
    <dd> Integer adder/subtracter or dual subtracter, possibly pipelined. The
    operation type defines the functioning mode: if 1, compute X-Y and X+Y; 
    if 0, compute X-Y and Y-X. 
 </dd>
</dl>
   <h4><i> Multi-operand Adders </i></h4>   
<dl>
   <dt><code style="color: blue;">IntNAdder wIn N</code></dt>
    <dd>Multi-operand integer adder using the hardware shift-registers (SRLs for Xilinx)
        available in current FPGAs. 
     </dd>
   <dt><code style="color: blue;">IntCompressorTree wIn N</code></dt>
    <dd>Multi-operand integer adder using compressor trees. High quality operator
    at the expense of synthesis time.
     </dd>
</dl>
   <h4><i> Multipliers </i></h4>   
<dl>     
  <dt><code style="color: blue;">IntMultiplier wInX wInY signed ratio</code></dt>
	<dd>The IntMultiplier operator now regroups in a transparent way multiple 
	possible architectures. The <i>signed</i> parameter controls whether or not  
	the inputs will be treated as 2's complement numbers for the signed case.
	The <i>ratio</i> parameter is a user knob for targeting a more DSP-oriented 
	architecture (<i>ratio=1</i>), or an architecture where some smaller 
	multiplications are casted in logic. A 0 value for the <i>ratio</i> will 
	generate an DSP-free architecture.</dd>
  <dt><code style="color: blue;">UnsignedIntMultiplier wInX wInY</code></dt>
     <dd>Generates a DSP-oriented multiplication architecture. Trades possible 
     DSP underutilization for logic and latency </dd>
  <dt><code style="color: blue;">SignedIntMultiplier wInX wInY</code></dt>
     <dd>Same as above but signed and no real support for Altera targets.</dd>
  <dt><code style="color: blue;">IntSquarer wInX wInY</code></dt>
    <dd>Same for squaring. For large multiplications on some FPGAs, it
    saves DSP blocks (your mileage may vary).</dd>
    <dd></dd>
  <dt><code style="color: blue;">IntKaratsuba wIn</code></dt>
    <dd> Multiplier that saves multiplications by trading them for additions.
    The TwoWaySplitting, ThreeWaySplitting and FourWaySplitting Karatsuba-Ofman algorithms are
    implemented. See this <a href="http://prunel.ccsd.cnrs.fr/docs/00/35/64/21/PDF/RR2009-03.pdf">article</a> for more details.</dd>
    <dd></dd>
  <dt><code style="color: blue;">IntTilingMultiplier wInX wInY ratio maxTimeInMinutes</code>
  <dd> Integer multiplier of two integers X and Y of sizes wInX and wInY
      using the tiling technique presented in this <a href="http://prunel.ccsd.cnrs.fr/docs/00/47/57/81/PDF/RR-LIP-2010-15.pdf">article</a>
      The <code>ratio</code> is a number in [0,1] and selects between DSP dominant architectures
      (<code>ratio</code> closer to 1) and logic dominant architectures for <code>ratio</code> closer to 0.  
      The algorithm uses an optimized backtracking approach in exploring the design space and 
      could therefore take a long time to get an optimal solution. The option <code>maxTimeInMinutes</code>
      is used to restrict the maximum amount of time that the algorithm can search for a solution. A value
      of <code>-1</code> for this parameter will find the best solution.</dd>
 	<dd></dd>
  <dt><code style="color: blue;">IntTruncMultiplier wInX wInY ratio error useLimits maxTimeInMinutes</code>
  <dd> Truncated integer multiplier of two integers X and Y of sizes wInX and wInY
      using the tiling technique and the specific truncation theory presented in this <a href="http://prunel.ccsd.cnrs.fr/docs/00/47/57/81/PDF/RR-LIP-2010-15.pdf">article</a>
      <code>error</code> gives the maximal allowed error produced by this operator. 
      Two different soft-multiplier expansion techniques can be selected using the
      <code>use limits</code> option but the recommended value is 1.
      </dd>
 	<dd></dd>


</dl>

<h3>Classical floating-point operators</h3> 

These operators are correctly rounded to the nearest, in a way
compatible with IEEE-754, with the exception that subnormal numbers
are flushed to zero.

<dl>
  <dt><code style="color: blue;">FPMultiplier wE wF</code></dt>
    <dd>A floating-point multiplier. The actual FloPoCo
      component supports different input and output sizes, but this is
      not available from the command line.</dd>
  <dt><code style="color: blue;">FPAdder wE wF</code></dt>
    <dd>A floating-point adder with a new, more compact single-path architecture.</dd>
  <dt><code style="color: blue;">FPAdderDualPath wE wF</code></dt>
    <dd>A previous FPAdder architecture. Trades a larger circuit size for a smaller latency.</dd>
  <dt><code style="color: blue;">FPAdder3Input wE wF</code></dt>
    <dd>A brand new 3-operand floating-point adder</dd>
  <dt><code style="color: blue;">FPDiv wE wF</code></dt>
    <dd>A floating-point divider.</dd>
  <dt><code style="color: blue;">FPSqrt wE wF</code></dt>
    <dd>A floating-point square root using the classical digit-recurrence algorithm. This implementation returns a correctly rounded result, uses no DSP nor RAM blocks and has low LUT usage. However, the latency can be as high as wF for high frequencies, and the frequency is limited for large wF. An alternative is FPSqrtPoly below.</dd>
  <dt><code style="color: blue;">FPSqrtPoly wE wF  CorrectlyRounded Degree</code></dt>
    <dd>A floating-point square root using a polynomial approximation. It consumes DSP and RAM blocks, but can reach higher frequencies than FPSqrt, and has lower latency. CorrectlyRounded (0/1) is a boolean selecting the rounding mode. If set to 0, the operator will only be faithful (last-bit accurate, but not necessarily correctly rounded). This saves a lot of resources. Degree is an integer (typically between 2 and 5) that defines the degree of the polynomial approximation, and allows the user to trade-off between DSP usage, latency and memory consumption. Lower degree means lower latency and DSP count, but larger consumption of embedded memory. </dd>
  <dt><code style="color: blue;">FPSquarer wE wF</code></dt>
    <dd>A floating-point squarer, using IntSquarer for the mantissa.</dd>
</dl>

<h3>Floating-point pipelined datapath generation </h3> 

Current FloPoCo release is proud to offer in <i>early alpha</i> version:

  <dt><code style="color: blue;">FPPipeline filename wE wF</code></dt>
    <dd> The operator receives the <i>filename</i> containing an
    untimed, untyped description (Python-like) of the datapath to be
    generated, together with the global precision of the operators to
    be used.
    
    Below are some examples of input files:
	<table border="1">
		<tr>
			<td>
    <code>
    /* Jacobi1D: */<br/>               
      j = (a0+a1+a2)*0.3333333333333333;  <br/> 
      output j; <br/> 
    </code>
    		</td>
			<td>
    <code>
    /* Horner: */  <br/>            
      p = a0+x*(a2+x*a2);  <br/>
      output p; <br/>
    </code>
    		</td>
 			<td>
    <code>
    /* 2D Norm: */ <br/>              
      r = sqrt(sqr(x0-x1)+sqr(y0-y1)); <br/>
      output r; <br/>
    </code>
    		</td>
   		</tr>
   		</table>
	<br/>
	The currently supported operators are: +,-,*,/, sqr(), sqrt(), exp(), log(). 
    </dd>

<h3>Long fixed-point accumulator, and derivatives</h3>
These operators are described in all the gory details
in <a href="http://prunel.ccsd.cnrs.fr/ensl-00268348/">this
article</a>.
<dl>
  <dt><code style="color: blue;">LongAcc wE_in wF_in MaxMSB_in LSB_acc MSB_acc</code></dt>
    <dd>Long fixed-point accumulator. By tuning
    the <code>MaxMSB_in</code>, <code>LSB_acc</code>
    and <code>MSB_acc</code> parameters to a given application, it
    allows one to bring rounding error to a provably arbitrarily small
    level (and in some case to avoid any rounding), for a very small hardware cost compared to using a
    floating-point adder for accumulation.
	 </dd>
  <dt><code style="color: blue;">DotProduct wE_in wF_X wF_Y MaxMSB_in LSB_acc MSB_acc</code></dt>
    <dd>Dot product operator. It feeds a long accumulator with the
      unrounded result of a floating-point multiplier, thus removing
      rounding errors from the multiplication as well.
	 </dd>
  <dt><code style="color: blue;">LongAcc2FP MaxMSB_in LSB_acc MSB_acc wE_out wF_out</code></dt>
    <dd>  Post-normalisation unit for LongAcc. It converts the output of a
      LongAcc or DotProduct (with the same parameters) into a floating-point
      number.
	 </dd>
</dl>



<h3>Constant multipliers</h3>


<p>We provide two techniques for building a multiplier by a constant. One is the good old KCM technique described by Chapman in 1994. It builds an operator whose size is independent on the constant, but grows with the size of the input. It is very efficient for very small input bit sizes and arbitrary constants. The other one is based on shift-and-add graphs, and is described in all the gory details in <a href="http://perso.ens-lyon.fr/florent.de.dinechin/recherche/publis/2008-ASAP-constmult.pdf">this article</a>. It will be more efficient for some constants. Some day we will be able to provide a uniform interface for these two families, in between you may want to try and synthesize both and pick up the best.</p>

<dl>
  <dt><code style="color: blue;">IntConstMult w c</code></dt>
    <dd>Integer constant multiplier using the shift-and-add technique: w is input size, c is the constant.</dd>

  <dt><code style="color: blue;"> IntIntKCM w c signedInput</code></dt>
    <dd>Integer constant multiplier using KCM: w is input size, c is the constant.</dd>

  <dt><code style="color: blue;"> FixRealKCM lsbIn msbIn signedInput lsbOut constant</code></dt>
    <dd>Faithful multiplier of a fixed-point input by a real constant. 
			The fixed-point format of the input is provided as two integers lsbIn and msbIn which give the weights of the least significand bit and the weight of the most significand bit. The input may be signed, or not.
      The constant is provided as a Sollya expression, e.g "log(2)". This operator is briefly described  in III.A.  of  <a href="http://perso.ens-lyon.fr/florent.de.dinechin/recherche/publis/2010-FPT-Exp.pdf">this article</a></dd>

  <dt><code style="color: blue;">FPConstMult wE_in wF_in wE_out wF_out cst_sgn cst_exp
  cst_int_sig</code></dt>
    <dd>Floating-point constant multiplier using the shift-and-add approach. 
			The constant is provided as sign, integral significand and integral exponent. Also described in <a href="http://perso.ens-lyon.fr/florent.de.dinechin/recherche/publis/2008-ASAP-constmult.pdf">this article</a>.</dd>


  <dt><code style="color: blue;">FPConstMultParser wE_in wF_in wE_out wF_out wF_C constant_expr</code></dt>
    <dd>
      Floating-point constant multiplier with a parser for the constant.
			This is basically the same as the previous, with a nicer interface:
      last argument is a Sollya expression between double quotes,e.g."exp(pi/2)".</dd>

  <dt><code style="color: blue;">FPRealKCM wE wF constantExpression</code></dt>
    <dd>
      Same as the previous but using the KCM algorithm.
		</dd>


  <dt><code style="color: blue;">FPConstMultRational wE_in wF_in wE_out wF_out a b</code></dt>
    <dd>
      Floating-point constant multiplier for a rational constant a/b. It uses the periodic representation of the constant to implement an optimal shift-and-add tree for it. This works well mostly for small a and b (scaled by whatever positive or negative power of two). This operator returns a correctly rounded result, therefore using it to multiply by 1/3 is bit-for-bit equivalent to using an IEEE-compliant division by 3.0. This operator is described in <a href="http://hal-ens-lyon.archives-ouvertes.fr/ensl-00610328">this article</a>. For division by b, you should also try FPConstDiv and compare the two obtained operators.</dd>
</dl>

<h3>Divider by a small integer constant</h3>
These operators are described in <a href="http://hal-ens-lyon.archives-ouvertes.fr/ensl-00642145/">this article</a>. 
<dl>
  <dt><code style="color: blue;">IntConstDiv w d alpha</code></dt>
    <dd> Euclidean division of input of size w by the small odd integer d. 
      Algorithm uses radix 2^alpha,   alpha=-1 means a sensible default.</dd>
</dl>
<dl>
  <dt><code style="color: blue;">FPConstDiv wE wF d</code></dt>
    <dd> Correctly rounded floating-point division by the small integer d. This works well for small, odd values of d.</dd>
</dl>
<dl>
  <dt><code style="color: blue;">FPConstDivExpert wE wF d e alpha</code></dt>
    <dd> Correctly rounded floating-point division by d.2^e, where d is a small odd integer. alpha=-1 means a sensible default.</dd>
</dl>


<h3>Floating-point elementary functions</h3>

<dl>
	<dt><code style="color: blue;">FPExp wE wF</code></dt>
	<dd>An  exponential operator, where both inputs and outputs  have <code>wE</code> bits exponent and
	<code>wF</code> bits significand. 
	</dd>

	<dt><code style="color: blue;">FPLog wE wF TableInsize</code></dt>
	<dd>A natural logarithm operator, where both inputs and outputs  have <code>wE</code> bits exponent and
	<code>wF</code> bits significand. The third allows for performance tuning. In doubt, set it to 0, which will default to something sensible. Otherwise, it defines the input size of the tables used by the operator, and should be between 6 and 15. See
<a href="http://perso.ens-lyon.fr/florent.de.dinechin/recherche/publis/2007-Arith.pdf">this article (improved version in preparation)</a>.
	</dd>
	
	<dt><code style="color: blue;">FPPow wE wF</code></dt>
	<dd> A floating-point <strong>pow</strong> function as described in C99 and IEEE 754-2008, where both inputs and outputs  have <code>wE</code> bits exponent and <code>wF</code> bits significand. This function (including its exceptional case management) is fully compatible with the  C99 standard, hence current default libms..
	</dd>

	<dt><code style="color: blue;">FPPowr wE wF</code></dt>
	<dd> A floating-point <strong>powr</strong> function as described in IEEE 754-2008, where both inputs and outputs  have <code>wE</code> bits exponent and
	<code>wF</code> bits significand. This function is a novelty of IEEE 754-2008, the difference with good old <code>pow</code> is that it is purely defined as powr(x,y)=e^(y*ln(x)), in particular in the definition of its exceptional cases. For instance, <code>pow</code> is defined for negative integer x, while <code>powr</code> returns NaN in such cases. 
	</dd>
</dl>	


<h3>Conversion operators</h3>
<dl>
	<dt><code style="color: blue;"> Fix2FP LSB MSB wE wF</code></dt>
	<dd>Convert a 2's complement fixed-point number in the bit range MSB...LSB (both
	included) into floating-point. Example: 
	  <code>Fix2FP 0 31 8 23</code> converts an input integer into a single-precision number.
	</dd>
	<dt><code style="color: blue;">InputIEEE wEI wFI wEO wFO</code></dt>
	<dd>Conversion from IEEE-754 formats.  Use <code>InputIEEE 8 23 wEO
	wFO</code> to convert from single-precision (or binary32) format,
	or <code>InputIEEE 11 52 wEO wFO</code> to convert from
	double-precision (or binary64) format. You may convert to a larger internal format or to a narrower one. Conversions are always correctly rounded. 
	</dd>
	<dt><code style="color: blue;">OurputIEEE wEI wFI wEO wFO</code></dt>
	<dd>Conversion to IEEE-754 formats. Not implemented yet. Do not hesitate to ask for it.
	</dd>
	<dt><code style="color: blue;">FP2FP wEI wFI wEO wFO</code></dt>
	<dd>Conversion from a FloPoCo format to another one.  Not implemented yet. Do not hesitate to ask for it.
	</dd>
</dl>	


<h3>Applications and examples</h3>


<dl>
	<dt><code style="color: blue;">Collision wE wF</code></dt>
	<dd>A collision operator. This is mostly a case study for a compound operator. It is described in 
	<a href="http://prunel.ccsd.cnrs.fr/ensl-00379154/">this article</a>.
	</dd>
</dl>	



<h3>Fixed point function evaluators</h3>

<em>These operators need libsollya! They will not be available otherwise.</em>
<dl>
	<dt><code style="color: blue;">FunctionEvaluator function wI wO degree</code></dt>
	<dt><code style="color: blue;">HOTBM function wI wO degree</code></dt>
	<dd>Fixed-point  implementation of a function.
	</dd>
</dl>
<p>FloPoCo provides two generic operators, <code>HOTBM</code>
and <code>FunctionEvaluator</code>, for evaluating an arbitrary
function in fixed point. They offer (almost) the same interface: the
description of a function between quotes (like <code>"sin(x)^2"</code>
ior <code>"sqrt(1+x)"</code>), input and output precisions (with a
difference of interpretation for outputs), and a polynomial degree. The function is assumed to have its input on [0,1], if you need a function on a different domain, you need to scale the input, e.g. use <code>"sin(pi/2*x)"</code> for a sine between 0 and pi/2.
</p>

<p>Both methods use piecewise polynomial approximation, the polynomial being "computed just right". The differences are the following.

<ul>
  <li> <code>HOTBM</code> (best described in 
<a href="http://perso.ens-lyon.fr/florent.de.dinechin/recherche/publis/2005-ASAP.pdf">this article</a>) evaluates the polynomial in parallel, and precomputes as much of the computation as it can, to  tabulate  it. As a consequence the operator has a very short delay, but doesn't scale well beyond 20 bits. In addition HOTBM is actually pre-FloPoCo code and the resulting VHDL is not pipelined. </li>
  <li> <code>FunctionEvaluator</code> (best described in 
<a href="http://prunel.ccsd.cnrs.fr/ensl-00470506/">this article</a>) evaluates the polynomial sequentially, using the Horner scheme. The latency is larger, but it scales to much larger precisions (64 bits), making efficient use of the embedded multipliers through the <code>IntMultiplier*</code> classes. The resulting operator is pipelined and can run to high frequencies.</li>
</ul>

<p>As both methods use a polynomial approximation, they work well for
functions which are regular enough. In mathematical terms, they should
be defined and n-times continuously differentiable on [0,1]. The code
is well tested for monotonic functions only. <b>Do not hesitate to
contact us for help on a given function.</b><p>

<p>For both HOTBM and FunctionEvaluator the input operand is interpreted as a positive fixed-point number,
with the point before the leftmost bit. The function to be implemented
is assumed to be well defined in [0;1[. </p>

<p>For HOTBM the output is a fixed-point number, where the first bit
is the sign and the point is placed right after it. Note that the
output is in fact <code>wO+1</code> bits wide. For
FunctionEvaluator, <code>wO</code> defines the weight of the least
significant bit of the result, and the actual output size depends on
the range of the function on [0,1]. Just try it.</p>

	  <p>Example:<br/>
		 <code>flopoco HOTBM "sin(x*Pi/2)" 16 16 3</code><br/>
		 <code>flopoco FunctionEvaluator "sin(x*Pi/2)" 32 32 4</code>
	  </p>

Interface variations on HOTBM:
<dl>
	<dt><code style="color: blue;">HOTBMFX func wE_in wF_in wE_out wF_out degree</code></dt>
	<dt><code style="color: blue;">HOTBMRange func wI wO degree xmin xmax scale</code></dt>
	<dd>	  <code>wE_in</code>, <code>wF_in</code>, <code>wE_out</code>, <code>wF_out</code>
	  are the width of the integral and fractional parts of the input and the output,
	  respectively.
	  [<code>xmin</code>, <code>xmax</code>] is the input domain of the
	  function, and <code>scale</code> is a scaling factor to be applied to
	  the output. 
	  
	   HOTBMFX version allows to select arbitrary fixed-point representations for the
		 input and output. Negative values are allowed.

	  HOTBMRange uses HOTBM after mapping [<code>xmin</code>,<code>xmax</code>[ to [0,1[, then multiplies the output by the scaling factor <code>scale</code>.</p>
	  
	  <p>Example:<br/>
		 <code>flopoco HOTBMFX "log2(1+2^(-x))" 2 8 -1 8 1</code>
	  </p>

	</dd>

</dl>



<p>Note that the  <code>HOTBM*</code> operators perform an exploration process that typically takes a few minutes for 16 bits, and may take hours for 24 bits.</p>



<h3>LNS</h3>

<p>These operators compute in the Logarithmic Number System. They are mostly useful
for low-precisions systems performing few additions and many multiplications, divisions
or square roots.</p>

<p>
<dl>
	<dt><code style="color: blue;">LNSAddSub wE wF</code></dt>
	<dd>
		LNS addition operator. Both operands and the output have
		<code>wE</code> integral bits and <code>wF</code> fractional
		bits in their exponents.
	</dd>
	<dt><code style="color: blue;">LNSMul wE wF</code></dt>
	<dd>
		LNS multiplication operator. Both operands and the output have
		<code>wE</code> integral bits and <code>wF</code> fractional
		bits in their exponents.
	</dd>
	<dt><code style="color: blue;">LNSDiv wE wF</code></dt>
	<dd>
		LNS division operator. Both operands and the output have
		<code>wE</code> integral bits and <code>wF</code> fractional
		bits in their exponents.
	</dd>
	<dt><code style="color: blue;">LNSSqrt wE wF</code></dt>
	<dd>
		LNS square root operator. Both input and output have
		<code>wE</code> integral bits and <code>wF</code> fractional
		bits in their exponents.
	</dd>
</dl>
</p>

<p>The implementation of LNS addition/subtraction is based on HOTBM to compute sums,
and uses cotransformation to evaluate differences. It is described in <a href="http://perso.ens-lyon.fr/sylvain.collange/papers/ArCo_Arith19.pdf">this article</a>.</p>

<h3>Test Benches</h3>


<p>The <code>TestBench</code> and <code>TestBenchfile</code> operators generate a test bench for
the operator which precedes it in the command line. The test vectors are generated from the specification of the operator (see the developer documentation of the <code>Operator::emulate()</code> method).</p>

<p>Test cases include both standard tests and random tests. The single parameter <code>n</code> specifies the number of random tests to generate. The pseudo-random number generator is initialised with <code>n</code> as the seed, so that the test bench will be deterministic for a given <code>n</code>. </p>

<p>We strongly advise that you test operators before using them, and we await your bug reports.</p>

<p>
<dl>
	<dt><code style="color: blue;">TestBench n</code></dt>
	<dd>
The test vectors are coded in the VHDL of the test bench, and can therefore be easily accessed and modified. In addition, they may include comments. However, this means that the compilation time of the test vectors is large, and this is not convenient beyond a few thousand tests.
<p>Example:<br/>
<code>flopoco HOTBM "sin(x*Pi/2)" 16 16 3 TestBench 1000</code>
</p>
	</dd>
	<dt><code style="color: blue;">TestBenchFile n</code></dt>
	<dd>
<code>TestBenchFile</code> is similar to <code>TestBench</code> but moves the test vectors to a separate file called  <code>test.input</code>. Thus the VHDL itself is very short, as is the compilation time. The simulation time is proportional to the number of tests. This scales to millions of test vectors, but is slightly less convenient in the debugging phase.

<p>If n=-2, and exhaustive test is generated. If n=-1, no file is generated.</p>

<p>Example:<br/>
<code>flopoco FPAdder 8 16  TestBenchFile 20000</code>
</p>
	</dd>
</dl>
</p>





<h3>Miscellanous</h3>
<dl>
  <dt><code style="color: blue;">Wrapper</code></dt>
    <dd>Produce a wrapper for the preceding operator: this operator simply adds registers before and after the preceding operator.
      It is useful in some cases, e.g. to get critical path information  including the delay of the first and last stages connected to registers, not to I/O.
	 </dd>
</dl>
</body>
</html>
